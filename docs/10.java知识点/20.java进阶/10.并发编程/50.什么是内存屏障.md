## 

## 什么是内存屏障

是一种**屏障指令**，它使得CPU或编译器对**屏障指令的前 或 后** 所发出的内存操作 **执行一个排序的约束**。也叫做内存栅栏 或栅栏指令





## 内存屏障的能力

1. 阻止屏障两边的指令的重排序

屏障后的指令不能排序到屏障前，屏障前的指令不能排序到屏障后。

2. 写数据的时候， 如果加了写屏障的话，强制把写缓冲的数据刷回到主内存中（可见性）
3. 读数据的时候，加了读屏障的话，会让工作内存/CPU高速缓存的数据失效，会重新到主内存中获取新数据。

综上可见：与可见性和指令重排序都有关



内存屏障分类

1. 读屏障：Load Barrier。在读指令之前插入读屏障。 会让工作内存/CPU高速缓存的数据失效，会重新到主内存中获取新数据。
2. 写屏障：store Barrier。在写指令之后插入写屏障，强制把写缓冲的数据刷回到主内存中



 ## 重排序和内存屏障的关系

1. 重排序可能会给程序带来问题，因此，有些时候，我们希望告诉JVM，这里不需要排序
2. 对于编译器的重排序，JMM会根据重排序的规则，禁止特定类型的编译器重排序
3. 对于处理器的重排序，java编译器在生成指令序列的适当位置，插入内存屏障指令，来禁止特定类型的处理器排序。



## JMM中的内存屏障

读读屏障 **LoadLoad Barriers**： Load1； LoadLoad ；Load2

> - 禁止重排序：访问Load2的读操作一定不会重排到Load1之前
>
> - 保证Load2在读取的时候，自己缓存内到相应的数据失效，Load2会去主内存获取最新的数据
>
> 设想一下为什么load1时不会有上面的清楚工作内存的数据呢？原因：假设我们都为变量a加上了内存屏障，那么第一次读变量a时，是不需要清楚缓存的，因为之前没有读过。



读写屏障 **LoadStore Barriers**：Load1；LoadStore；Store2

> 禁止重排序：一定是Load1读取到数据完成后，才能让Store2及其之后的写出操作的数据，被其它线程看到



写写屏障 **StoreStore Barriers**：Store1；StoreStore；Store2

> - 禁止重排序：一定是Store1的数据写出到主内存完成后，才能让store2及其之后的写出操作的数据，被其它县城看到
> - 还可以保证Store1指令写出去的数据，会强制被刷新到主内存中



写读屏障**StoreLoad Barriers** ：Store1；StoreLoad；Load2

> - 禁止重排序：一定是store1的数据写出到主内存完成后，才能让Load2来读取数据
>
> - 同时保证：强制把写写缓冲区的数据刷回到主内存中；让工作内存高速缓存当中缓存数据失效，重新到主内存中获取新的数据





## 为什么StoreLoadBarriers是最重的？

重：就是跟内存交互次数多，交互延迟较大、消耗资源多



LoadLoad只有读屏障功能

StoreStore只有写屏障功能

**而StoreLoad同时拥有所有的功能**



## 扩展

​	这些屏障指令并不是处理器真实的执行指令，他们只是JMM定义出来的、跨平台的指令。

​	因为不同硬件实现内存屏障的方式并不相同，JMM为了屏蔽这些底层硬件平台的不同，抽象出了这些内存指令屏障，在运行的时候，由JVM来为不同的平台生成效应的机器码。



这些内存屏障指令，在不同的硬件平台上，可能会在一些优化，从而只支持部分的JMM的内存屏障指令



例如在x86机器上，就只有StoreLoad操作，其他都不支持，仅仅是个空操作



**volatile使用的就是StoreLoad屏障**













