

Transforme由注意力机制组成。transformer仅由注意力和前馈神经网络组成

Transformer也是NLP自然语言处理模型



Transformer对文本的理解：

![image-20230916121722080](https://2290653824-github-io.oss-cn-hangzhou.aliyuncs.com/image-20230916121722080-20230916121725065.png)

其中高亮的词指的是同一个人。这对于人来理解相当的容易，但是对于机器来理解就很难了。对机器理解自然语言来说，掌握句子中这些关系和单词序列至关重要。**这就是 Transformer 概念发挥主要作用之处。**





![image-20230916132643457](https://2290653824-github-io.oss-cn-hangzhou.aliyuncs.com/image-20230916132643457.png)





















参考：

https://www.youtube.com/watch?v=dIyQl99oxlg&list=RDCMUCGWYKICLOE8Wxy7q3eYXmPA&start_radio=1&rv=dIyQl99oxlg&t=30

https://www.youtube.com/watch?v=n67w5tmHcAI